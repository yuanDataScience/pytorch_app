{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module4_Demo3_Debiase_Word_Embeddings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsFqZQAJ8UplkzuuUsBPpA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/implement-nlp-word-embedding/blob/main/module4/Module4_Demo3_Debiase_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Debiasing word embeddings"
      ],
      "metadata": {
        "id": "jzcH2ze5A83R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data and library"
      ],
      "metadata": {
        "id": "LTIImi8JIajZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYSA42Eg77Fq",
        "outputId": "23d48dbf-a83c-4347-fedc-318c75e567a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f glove.6B.zip ]; then\n",
        "  wget -O glove.6B.zip https://nlp.stanford.edu/data/glove.6B.zip\n",
        "  unzip glove.6B.zip\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1TDAZW-mIZ",
        "outputId": "9c88be9f-57f3-46f4-bfb4-b2c6844f8f23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "Ejablm5_-tSQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the bias of the embedding"
      ],
      "metadata": {
        "id": "sGmY111lIfew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec(glove_input_file=\"glove.6B.50d.txt\", word2vec_output_file=\"emb_word2vec_format.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnGXDOom-ueR",
        "outputId": "f3a63abb-511a-4b74-fda1-8b8de6a50847"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('emb_word2vec_format.txt')"
      ],
      "metadata": {
        "id": "G3MhwM8r-wdi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "pairs = [('father', 'mother'), ('man', 'computer'), ('tennis', 'couch')]\n",
        "for word_tuple in pairs:\n",
        "  print(f'Words: {word_tuple} and similarity is {1-spatial.distance.cosine(model[word_tuple[0]], model[word_tuple[1]])}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxJjfFnJ-zXP",
        "outputId": "1c4180b3-8274-4f70-e937-41af3e46dbce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: ('father', 'mother') and similarity is 0.8909038305282593\n",
            "Words: ('man', 'computer') and similarity is 0.4015541970729828\n",
            "Words: ('tennis', 'couch') and similarity is 0.2106797844171524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "not_normalized_gender_vector = model['man'] - model['woman']\n",
        "gender_vector = not_normalized_gender_vector/np.sqrt(np.dot(not_normalized_gender_vector, not_normalized_gender_vector))\n",
        "for word in ['sports', 'politics', 'economy', 'digits', 'love', 'policewoman', 'equality', 'technology', 'receptionist']:\n",
        "  print(f'Gender_vector similarity to {word} is {1-spatial.distance.cosine(gender_vector, model[word])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDeoqBrY_rvV",
        "outputId": "b2d617cf-6fa0-4e11-a2b4-5cf6987f6a8b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender_vector similarity to sports is 0.17934592068195343\n",
            "Gender_vector similarity to politics is 0.012288778088986874\n",
            "Gender_vector similarity to economy is 0.0778021365404129\n",
            "Gender_vector similarity to digits is 0.02250431478023529\n",
            "Gender_vector similarity to love is 0.006848746445029974\n",
            "Gender_vector similarity to policewoman is -0.26551297307014465\n",
            "Gender_vector similarity to equality is -0.17352420091629028\n",
            "Gender_vector similarity to technology is 0.13193733990192413\n",
            "Gender_vector similarity to receptionist is -0.33077940344810486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how *man* is \"closer\" and \"more related\" to sports and technology, while *woman* is \"more related\" to equality and receptionist."
      ],
      "metadata": {
        "id": "7Ch3oYdgAhV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debiase non-gender words"
      ],
      "metadata": {
        "id": "qJpbOzm-A-eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neutralize(word, gender_vector, model):\n",
        "  word_projection_in_gender = np.dot(model[word], gender_vector)*gender_vector\n",
        "  return model[word] - word_projection_in_gender"
      ],
      "metadata": {
        "id": "2sNpkuzrAZJO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in ['sports', 'politics', 'economy', 'digits', 'love', 'policewoman', 'equality', 'technology', 'receptionist']:\n",
        "  print(f'Gender_vector similarity to neutralized {word} is {1-spatial.distance.cosine(gender_vector, neutralize(word, gender_vector, model))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08mMYhikB8n6",
        "outputId": "7d1d22b6-73fe-4abe-a684-7c959366263e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender_vector similarity to neutralized sports is 1.3393989917176441e-08\n",
            "Gender_vector similarity to neutralized politics is -1.424718121256774e-10\n",
            "Gender_vector similarity to neutralized economy is 1.4764868438987833e-08\n",
            "Gender_vector similarity to neutralized digits is 6.64072086209444e-09\n",
            "Gender_vector similarity to neutralized love is -2.858495662394489e-10\n",
            "Gender_vector similarity to neutralized policewoman is -4.062933811610492e-08\n",
            "Gender_vector similarity to neutralized equality is 5.002243064211598e-09\n",
            "Gender_vector similarity to neutralized technology is 2.2143172628830143e-08\n",
            "Gender_vector similarity to neutralized receptionist is 1.0329419097843129e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equalize gender specific words"
      ],
      "metadata": {
        "id": "z6a97-9XDwJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def equalize(word1, word2, gender_vector, model):    \n",
        "    word_rep_1 = model[word1]\n",
        "    word_rep_2 = model[word2]\n",
        "\n",
        "    average_rep = (word_rep_1 + word_rep_2) / 2\n",
        "\n",
        "    average_in_gender_vector = np.dot(average_rep, gender_vector)* gender_vector\n",
        "    average_in_non_gender_vector = average_rep - average_in_gender_vector\n",
        "\n",
        "    word_1_in_gender_vector = np.dot(word_rep_1, gender_vector) * gender_vector\n",
        "    word_2_in_gender_vector = np.dot(word_rep_2, gender_vector) * gender_vector\n",
        "        \n",
        "    corrected_word_1_in_gender_vector = np.sqrt(np.abs(1 - np.sum(average_in_non_gender_vector * average_in_non_gender_vector))) * (word_1_in_gender_vector - average_in_gender_vector) / np.linalg.norm(word_rep_1 - average_in_non_gender_vector - average_in_gender_vector)\n",
        "    corrected_word_2_in_gender_vector = np.sqrt(np.abs(1 - np.sum(average_in_non_gender_vector * average_in_non_gender_vector))) * (word_2_in_gender_vector - average_in_gender_vector) / np.linalg.norm(word_rep_2 - average_in_non_gender_vector - average_in_gender_vector)\n",
        "\n",
        "    e1 = corrected_word_1_in_gender_vector + average_in_non_gender_vector\n",
        "    e2 = corrected_word_2_in_gender_vector + average_in_non_gender_vector\n",
        "\n",
        "    return e1, e2"
      ],
      "metadata": {
        "id": "4R6hSU11COHJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (word1, word2) in [('man', 'woman'), ('policeman', 'policewoman'), ('actor', 'actress')]:\n",
        "  e1, e2 = equalize(word1, word2, gender_vector, model)\n",
        "  print(f'Gender_vector similarity to equalized pair {(word1)} is {1-spatial.distance.cosine(gender_vector, e1)}')\n",
        "  print(f'Gender_vector similarity to equalized pair {(word2)} is {1-spatial.distance.cosine(gender_vector, e2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRFY6rxEF5Wp",
        "outputId": "20c414a7-de31-435a-9832-e9b66d5acb82"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender_vector similarity to equalized pair man is 0.7004363536834717\n",
            "Gender_vector similarity to equalized pair woman is -0.7004364132881165\n",
            "Gender_vector similarity to equalized pair policeman is 0.22585387527942657\n",
            "Gender_vector similarity to equalized pair policewoman is -0.22585390508174896\n",
            "Gender_vector similarity to equalized pair actor is 0.6083327531814575\n",
            "Gender_vector similarity to equalized pair actress is -0.6083329916000366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mixing it all together"
      ],
      "metadata": {
        "id": "wVNyKDHeIkvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Checking the new similarity of equalized man/woman with original neutralized words')\n",
        "e1, e2 = equalize('man', 'woman', gender_vector, model)\n",
        "for word in ['sports', 'politics', 'economy', 'digits', 'love', 'policewoman', 'equality', 'technology', 'receptionist']:\n",
        "  print(f'Gender_vector similarity to neutralized {word} is {1-spatial.distance.cosine(e1, neutralize(word, gender_vector, model))}')\n",
        "  print(f'Gender_vector similarity to neutralized {word} is {1-spatial.distance.cosine(e2, neutralize(word, gender_vector, model))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkKLJ-24HVHX",
        "outputId": "3f4ebed0-9611-44b8-88c9-d0ddd1ce86d7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the new similarity of equalized man/woman with original neutralized words\n",
            "Gender_vector similarity to neutralized sports is 0.2870727479457855\n",
            "Gender_vector similarity to neutralized sports is 0.28707271814346313\n",
            "Gender_vector similarity to neutralized politics is 0.3767041563987732\n",
            "Gender_vector similarity to neutralized politics is 0.3767041563987732\n",
            "Gender_vector similarity to neutralized economy is 0.23900271952152252\n",
            "Gender_vector similarity to neutralized economy is 0.23900270462036133\n",
            "Gender_vector similarity to neutralized digits is 0.06872960180044174\n",
            "Gender_vector similarity to neutralized digits is 0.06872957199811935\n",
            "Gender_vector similarity to neutralized love is 0.525387704372406\n",
            "Gender_vector similarity to neutralized love is 0.5253877639770508\n",
            "Gender_vector similarity to neutralized policewoman is 0.27720245718955994\n",
            "Gender_vector similarity to neutralized policewoman is 0.2772025465965271\n",
            "Gender_vector similarity to neutralized equality is 0.16693219542503357\n",
            "Gender_vector similarity to neutralized equality is 0.16693225502967834\n",
            "Gender_vector similarity to neutralized technology is 0.19151872396469116\n",
            "Gender_vector similarity to neutralized technology is 0.19151873886585236\n",
            "Gender_vector similarity to neutralized receptionist is 0.2658967971801758\n",
            "Gender_vector similarity to neutralized receptionist is 0.2658967971801758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we could effectively make the model unbiased by making each of the words equally likely to refer to woman or man. This can be done with any type of bias"
      ],
      "metadata": {
        "id": "AOGoaG8VIJLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GZ-0ADTCG_hh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}