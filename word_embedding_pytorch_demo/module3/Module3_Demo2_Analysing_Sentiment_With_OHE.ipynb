{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFd/DRLDTdfR33R2f0xT0G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/implement-nlp-word-embedding/blob/main/module3/Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing Sentiment"
      ],
      "metadata": {
        "id": "QlJeKdJfTPMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first import everything and load the dataset"
      ],
      "metadata": {
        "id": "epE01e6NbbMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri00gAaqSzrq",
        "outputId": "900cf3f1-772c-42cb-c14a-fbe2a03da17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "import torch\n",
        "from torch import nn\n",
        "import seaborn as sns\n",
        "nltk.download('punkt')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(rc={'figure.figsize':(20,20)})\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHuUsDMlTXhM",
        "outputId": "611fd60c-0bf7-43b1-fb65-9d04a2c0baef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "Uq4-oO3KTnbQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
        "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
        "\n",
        "# Define X and y.\n",
        "X = yelp_best_worst.text\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})\n"
      ],
      "metadata": {
        "id": "i32aK_G6TZl9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing the train_test split and defining model"
      ],
      "metadata": {
        "id": "quWimVZjbemw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gPK5YmDMTbby"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer()\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "X_test_dtm = vect.transform(X_test)"
      ],
      "metadata": {
        "id": "v0LSrnpiUs8p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.Tensor(X_train_dtm.toarray()).to(device)\n",
        "X_test_tensor = torch.Tensor(X_test_dtm.toarray()).to(device)\n",
        "y_train = torch.Tensor(y_train.values).type(torch.LongTensor).to(device)\n",
        "y_test = torch.Tensor(y_test.values).type(torch.LongTensor).to(device)"
      ],
      "metadata": {
        "id": "SwdtffgTVRM0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(X_train_tensor.shape[1], 2),\n",
        "  nn.LogSoftmax(dim = 1)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "Ip1U599PVXrg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X):\n",
        "  return model(X).to(device)\n",
        "\n",
        "def loss(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "def metric(y_pred, y):  # -> accuracy\n",
        "  return (1 / len(y)) * ((y_pred.argmax(dim = 1) == y).sum())\n"
      ],
      "metadata": {
        "id": "RB_PGA_7WTC5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's verify the metric makes sense"
      ],
      "metadata": {
        "id": "KMQJasS-YOpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model(X_train_tensor).to(device)\n",
        "y_train_pred.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbKjRHJyWbTU",
        "outputId": "5a48e86e-0f7a-4e0f-bbe9-4463435d3868"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1,  ..., 1, 1, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_train_pred.argmax(dim = 1) == y_train).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnE5Aj0WfoX",
        "outputId": "d6130265-8a19-457c-b117-5861b091e487"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1619, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric(y_train_pred, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMIbTz7mWm-v",
        "outputId": "fd37dde1-c6ac-46db-d3f6-0d346db926e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4954, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del y_train_pred"
      ],
      "metadata": {
        "id": "JD4jGHO3YelM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The training routine"
      ],
      "metadata": {
        "id": "ROXVUovhYRWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "U80Pu2e8X3Il"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "  y_pred = forward(X_train_tensor)\n",
        "  xe = loss(y_pred, y_train)\n",
        "  accuracy = metric(y_pred, y_train)\n",
        "  xe.backward()\n",
        "  if i % 100 == 0:\n",
        "    print(\"Loss: \", xe, \" Accuracy \", accuracy.data.item())\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kchBdsMYT94",
        "outputId": "9e28bd7a-d85f-47e7-a315-60f6791b8654"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6942, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.4954100549221039\n",
            "Loss:  tensor(0.1341, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9914320707321167\n",
            "Loss:  tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9951040744781494\n",
            "Loss:  tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9963280558586121\n",
            "Loss:  tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9972460269927979\n",
            "Loss:  tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9972460269927979\n",
            "Loss:  tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9981640577316284\n",
            "Loss:  tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9984700083732605\n",
            "Loss:  tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9987760186195374\n",
            "Loss:  tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9987760186195374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = forward(X_test_tensor)\n",
        "print(f'Model accuracy is {metric(y_test_pred, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlU4QbIPYrPc",
        "outputId": "de96d398-f3dc-4ccf-e05a-e33944b0bb0a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is 0.8948655724525452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some manual validation"
      ],
      "metadata": {
        "id": "tNqRJ0wCbXMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = np.array([\"This place was fantastic\"])\n",
        "vectorized_review = torch.Tensor(vect.transform(review).toarray()).to(device)"
      ],
      "metadata": {
        "id": "EgO7d2LdbYhD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = forward(vectorized_review)\n",
        "prediction.argmax(dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icVOjVFybsU-",
        "outputId": "e80d0102-b2e7-400b-b237-06269a3ff371"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the model predicted correctly that the review was positive!"
      ],
      "metadata": {
        "id": "VBSc6m2LcPfk"
      }
    }
  ]
}